# METHODOLOGY
## Data
This study investigates B2B marketing strategies in cloud computing services, focusing on IT enterprises and their customer perspectives. Cloud services fundamental to digital transformation provide critical infrastructure including compute instances, domain/DNS services, and GPU acceleration, which underpin modern internet operations (jain_procuring_2025; jain_hybrid_2019). Leading providers fierce and strong competition and are using together in multi-cloud configurations, such as Amazon Web Services (AWS), Microsoft Azure, Google Cloud and IBM (jain_procuring_2025; jain_hybrid_2019) ,  leverage YouTube as a primary B2B marketing channel to showcase solutions. The global cloud market, dominated by U.S.-based firms with worldwide data centers, was valued at 766 billion in 2023 and expected 1.3 trillion by 2025, driven by digitalization and AI advancements (Statistica, 2025). Notably, AI services (e.g., ChatGPT) rely on cloud infrastructure, with Azure powering Microsoft’s deployments. This study focuses on the four largest cloud providers: AWS (~30% market share) Microsoft Azure (~21%) Google Cloud (~12%) IBM, a legacy firm with strong enterprise/government adoption due to its research capabilities (gans_choosing_2021; jain_hybrid_2019; watson_will_2021) . Given YouTube’s decade-long use in B2B marketing, this study analyzes horizontal video content as a key engagement tool (M. (Magie) Cheng & Zhang, 2025b). With 1 million subscribers serving as a "mega-influencer" (mardon_how_2023), firms strategically deploy video to demonstrate solutions. The view counts in video content have low and high persomeinig videos like in FIGURE1 , in our study we conceptualize the the main To analyse the impact of similarity we highlight the 1 qurtyle lest engagent one and the upper one most engagement one. We chaceck the similarity wbight the similary from most engagent content.
## Similarity
To analyze content strategy similarity among rival firms on youtube, we measure how closely each firm’s top un underperfomrning content aligns with that of its top three competitors. Trasformar are not noly use in academia but the main architecture from more popular embedding service as a base concept in openAI embedding or Amazon Titan Text Embeddings , BERT (Bidirectional Encoder Representations from Transformers) generates embeddings that are highly contextualized and effective for various NLP tasks. The embedding size in BERT refers to the dimensionality of the vector representation for each token in the input sequence. Using Embeddings improve calculating pairwise similarity using term frequency–inverse document frequency (TFIDF) vectors (lysyakov_retailer_2025),
Attention(Q,K,V )= softmax(〖QK〗^⊤/√(d_k ))V 
In the transformer architecture, Q (Query), K (Key), and V (Value) are vectors derived from the input token embeddings. Each token's embedding is linearly transformed into three separate vectors: the query vector Q represents what the token is searching for in other tokens; the key vector K represents the characteristics of each token that queries will compare against; and the value vector V contains the actual information of the tokens that is aggregated. The attention mechanism computes a similarity score between Q and all K vectors using a scaled dot product, which determines how much focus (weight) each token's value V should receive when generating the output embedding. This allows the model to dynamically "attend" to the most relevant parts of the input sequence for each token.
Cosine Similarity=  (A⋅B)/‖A‖‖B‖ 
where A⋅B is the dot product of the vectors, ‖A‖ is the magnitude (Euclidean norm) of vector A, and ‖B‖  is the magnitude of vector B. This formula computes the cosine of the angle between the two vectors, resulting in a value between -1 and 1. A value of 1 indicates that the vectors point in the same direction (high similarity), 0 means they are orthogonal (no similarity), and -1 means they point in opposite directions (completely dissimilar). Cosine similarity is widely used in vector embeddings to capture semantic similarity by focusing on the orientation of vectors rather than their magnitudes.
## Effect of content similarity on engagement
To examine how similarity or dissimilarity influences user engagement, we estimate the following model:
Y_it=β_0+ β_1 〖Similarity〗_it+ α_i+ δ_y+ u_it
The key independent variable in the model is 〖Similarity〗_it is calculated as the average cosine similarity between each firm and competitors for every year. We structure the panel data , as this frequency provides a sufficient volume of videos to assess content strategy similarities across firms, even when their posting frequencies vary. In additional robustness tests, we also employ monthly data. The primary outcome variable Y_it captures YouTube engagement, measured by the total number of likes plus views in a year. As control variables, we include the number of videos and the number of followers a firm has in a given year.We further control for firm-specific factors using  α_i firm fixed effects, temporal variations using δ_y   year fixed effects.
To investigate the semantic characteristics of high- and low-performing video content, we first generate vector embeddings for each video title using a pre-trained sentence transformer model, thereby transforming textual titles into dense numeric vectors that encapsulate their underlying semantic meanings. These embeddings are then analyzed on a monthly basis, where videos are stratified into two performance-based groups—Top Quartile (highest-performing) and Bottom Quartile (lowest-performing)—according to their respective engagement metrics. For each month, we compute three types of cosine similarity scores between title embeddings: Top_vs_Top, which reflects the average semantic similarity among all pairs of top-quartile videos; Low_vs_Low, representing the analogous average for bottom-quartile videos; and Low_vs_Top, capturing the average similarity between each bottom-quartile video and every top-quartile video within the same month. Cosine similarity, ranging from -1 to 1, quantifies the angular proximity between two vectors, with higher values indicating greater semantic alignment. By averaging these pairwise similarity scores across all relevant video pairs within each category, we derive a single representative score per month for each of the three similarity dimensions, enabling a systematic comparison of semantic patterns associated with video performance tiers. The top performance videos have s slope positive slope while the low performance have a negative one, it means. While the technology evolve and reach more people the similarity decrese , while the other low perfomrace content similarity increase.
Economtric model presents the results of an OLS regression analyzing the relationship between video content similarity and viewer engagement, as captured by view count. The dependent variable is viewCount, and the key independent variable is avg_top_similarity, which measures the average cosine similarity of a video’s content with that of its top competitors. The regression is based on panel data spanning multiple months. The model explains a small but statistically significant portion of the variance in view counts, with an R-squared of 0.006 and an adjusted R-squared of 0.006. The F-statistic of 17.63 (p < 2.77e-05) indicates that the model as a whole is statistically significant. Notably, the coefficient for avg_top_similarityis negative and highly significant (coef = -7.53e+04, p < 0.001), suggesting that as the average similarity between a video and its top competitors increases, the view count tends to decrease substantially. This pattern indicates that, similar to how some firms’ social media content diverges from that of their traditional competitors, videos that are less similar (i.e., more distinct) in content to their top competitors may be associated with higher viewer engagement. Such a finding mirrors the broader observation across competitive clusters where differentiation—rather than similarity—may drive attention and visibility.